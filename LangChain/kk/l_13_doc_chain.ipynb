{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Document Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the environment\n",
    "def get_mistral_api_key():\n",
    "    key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    if not key:\n",
    "        key = getpass.getpass(\"Enter your Mistral API key: \")\n",
    "        os.environ[\"MISTRAL_API_KEY\"] = key\n",
    "    return key\n",
    "\n",
    "# Get the Mistral API key\n",
    "mistral_api_key = get_mistral_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL1=\"https://techcrunch.com/2024/02/27/microsoft-made-a-16-million-investment-in-mistral-ai/\"\n",
    "URL2=\"https://techcrunch.com/2024/03/28/ai21-labs-new-text-generating-ai-model-is-more-efficient-than-most/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader([URL1,URL2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[(\"system\", \"What models are launched by Mistral and AI21 Labs:\\n\\n{context}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(model=\"mistral-small-2501\", temperature=0, max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Models Launched by Mistral AI and AI21 Labs\\n\\n#### Mistral AI\\nMistral AI, a Paris-based AI startup, has launched several significant models and initiatives:\\n\\n1. **Mistral Large**:\\n   - **Description**: Mistral Large is a flagship large language model designed to rival top-tier models like OpenAI’s GPT-4 and Claude 2.\\n   - **Access**: Unlike previous Mistral AI releases, Mistral Large is not open source. Developers can access the model through Mistral’s own API platform.\\n   - **Distribution**: Mistral AI has signed a distribution partnership with Microsoft, allowing Azure customers to access Mistral’s models through Azure’s model catalog.\\n\\n2. **Investment and Partnerships**:\\n   - **Microsoft Investment**: Microsoft invested €15 million ($16.3 million) in Mistral AI as part of a Series A extension. This investment will convert into equity in Mistral’s next funding round.\\n   - **Valuation**: Mistral AI reached a valuation of about $2 billion following its most recent funding round in December 2023.\\n\\n#### AI21 Labs\\nAI21 Labs has also made significant strides with their new AI model:\\n\\n1. **Jamba**:\\n   - **Description**: Jamba is a text-generating and -analyzing model that can handle up to 140,000 tokens, translating to around 105,000 words or 210 pages.\\n   - **Architecture**: Jamba uses a combination of transformer and state space model (SSM) architectures. It leverages Mamba, an open-source SSM model, to achieve high throughput on long contexts.\\n   - **Performance**: Jamba claims to deliver three times the throughput on long contexts compared to transformer-based models of comparable sizes.\\n   - **License**: Released under the Apache 2.0 license, Jamba is intended for research purposes and does not include safeguards against generating toxic text or mitigating potential bias. A fine-tuned, safer version is expected to be released soon.\\n\\n### Key Points\\n- **Mistral AI** focuses on developing high-performance language models and has secured significant investment from Microsoft, positioning itself as a strong competitor in the AI landscape.\\n- **AI21 Labs** introduces Jamba, a model that leverages innovative architecture to handle large contexts efficiently, making it a notable addition to the AI model ecosystem.\\n\\nThese developments highlight the ongoing innovation and competition in the AI industry, with both companies pushing the boundaries of what is possible with large language models.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"context\": data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a37cff-5e94-4fa8-b263-bee57d018331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ollama in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (0.4.4)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from ollama) (2.10.3)\n",
      "Requirement already satisfied: anyio in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.0)\n",
      "Requirement already satisfied: certifi in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-search-results in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->google-search-results) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->google-search-results) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numexpr in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.10.2)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from numexpr) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in /Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages (1.5.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-ollama\n",
    "%pip install -U ollama\n",
    "%pip install python-dotenv\n",
    "%pip install google-search-results\n",
    "%pip install numexpr\n",
    "%pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f05f3e-cc8d-4a74-97a3-50e0fdfb9227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097b5072-7d5c-4279-bdb0-b7d2d2ee3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.2-vision\",\n",
    "    temperature = 0,\n",
    "    # num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = OllamaLLM(model=\"llama3.2-vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4001681-4569-4fb8-9404-93b47e13dd67",
   "metadata": {},
   "source": [
    "### Creating a LangSmith client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6502569-c56d-48a3-9354-8b39a3169fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c42542e-a37d-4f17-94b8-04f77e7b6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e9ea70-d567-4282-9118-b2d1eb8483a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b4810-40fe-44b8-aeb1-3a6a3170e2be",
   "metadata": {},
   "source": [
    "### Initialize an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dc9cf8-ed73-471b-bff8-c2128d974a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<AgentType.ZERO_SHOT_REACT_DESCRIPTION: 'zero-shot-react-description'>, <AgentType.REACT_DOCSTORE: 'react-docstore'>, <AgentType.SELF_ASK_WITH_SEARCH: 'self-ask-with-search'>, <AgentType.CONVERSATIONAL_REACT_DESCRIPTION: 'conversational-react-description'>, <AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION: 'chat-zero-shot-react-description'>, <AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION: 'chat-conversational-react-description'>, <AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION: 'structured-chat-zero-shot-react-description'>, <AgentType.OPENAI_FUNCTIONS: 'openai-functions'>, <AgentType.OPENAI_MULTI_FUNCTIONS: 'openai-multi-functions'>]\n"
     ]
    }
   ],
   "source": [
    "# Print available agent types\n",
    "print(list(AgentType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f8b782-5f03-4e57-b429-bcdaecb6dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/5skqq8p925lbtt_m8d7msnkc0000gn/T/ipykernel_72043/595443142.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdbe78-8062-4042-95fd-03116082b220",
   "metadata": {},
   "source": [
    "### Input processing with exception handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b793c3e-f1a4-41ef-9eb2-9380c2d3cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/5skqq8p925lbtt_m8d7msnkc0000gn/T/ipykernel_72043/921604161.py:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return await agent.run(input_example)\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define a list of input examples\n",
    "inputs = [\n",
    "    \"How many go on vacation to Maldives in 2023?\",\n",
    "    \"Who is the faster man in the World?\",\n",
    "    \"What is Obama's first daughter's age?\",\n",
    "    \"What is the distance of Africa to America?\",\n",
    "    \"What was the number of games Lionel Messi played in Inter Miami?\",\n",
    "    \"What was the total number of male in America?\",\n",
    "    \"How many artistes performed at 02 Arena in London in 2023?\",\n",
    "    \"What is 10 raised to power of 20?\",\n",
    "    \"Who is the best international news station?\",\n",
    "    \"What is value of 10000 divided by 2?\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "async def run_agent(agent, input_example):\n",
    "    try:\n",
    "        return await agent.run(input_example)\n",
    "    except Exception as e:\n",
    "        # Handle exceptions, if any\n",
    "        return e\n",
    "\n",
    "# Create an event loop and gather results\n",
    "async def main():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    for input_example in inputs:\n",
    "        results.append(loop.create_task(run_agent(agent, input_example)))\n",
    "    await asyncio.gather(*results)\n",
    "\n",
    "# Run the main event loop\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dd5ac07-4975-44f9-9fbc-bf72a67c83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers.langchain import wait_for_all_tracers\n",
    "wait_for_all_tracers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6e4d7-fa7a-4f5c-b084-24d77b861fc4",
   "metadata": {},
   "source": [
    "## Evaluating and testing AI applications using LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd9a58-f921-454f-91b1-1769c99c12b6",
   "metadata": {},
   "source": [
    "### Creating a LangSmith dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "839c16eb-8de9-4fd0-b323-de96fd621a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique identity using UUID\n",
    "unique_identity = str(uuid.uuid4())\n",
    "\n",
    "dataset_name = f\"calculator-example-dataset-{unique_identity}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name, description=\"A calculator dataset\"\n",
    ")\n",
    "\n",
    "runs = client.list_runs(\n",
    "    project_name=os.environ[\"LANGCHAIN_PROJECT\"],\n",
    "    execution_order=1,\n",
    "    error=False,\n",
    ")\n",
    "for run in runs:\n",
    "    client.create_example(inputs=run.inputs, outputs=run.outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7eabd-9694-46bf-9496-a1c2ef3dbe86",
   "metadata": {},
   "source": [
    "### Initializing new agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d1cd53a-c4fd-4fdd-b456-ed747b776afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "llm = ChatOllama(model=\"mistral-nemo\", temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "def agent_factory():\n",
    "    return initialize_agent(tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80aaef-3f4b-4665-b4ba-c2ecc067cbcb",
   "metadata": {},
   "source": [
    "### Customizing and configuring evaluation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f62c9d-148c-4b60-83f2-bceab1e9d814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4abef698-5a16-4406-8e1f-be472f140bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51bce057-c6f0-4509-a040-e88c81e2cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the evaluation LLM\n",
    "# evaluation_llm = OllamaLLM(model=\"llama3.2-vision\")\n",
    "evaluation_llm = ChatOpenAI(model=\"gpt-4o-mini\")  # or replace with a supported model\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "\n",
    "    evaluators=[\n",
    "\n",
    "        EvaluatorType.QA,\n",
    "\n",
    "        EvaluatorType.EMBEDDING_DISTANCE,\n",
    "\n",
    "        RunEvalConfig.LabeledCriteria(\"helpfulness\"),\n",
    "\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\n",
    "                \"fifth-grader-score\": \"Do you have to be smarter than a fifth grader to answer this question?\"\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    custom_evaluators=[],\n",
    "    llm=evaluation_llm,  # Provide the evaluation LLM here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697adcd-cd92-45e0-ac73-177d6a24236e",
   "metadata": {},
   "source": [
    "### Executing the agent and evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19d8ba7c-75c9-4717-964c-c807a9e436ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shatten/.pyenv/versions/3.11.2/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3506: LangChainPendingDeprecationWarning: The tags argument is deprecated and will be removed in a future release. Please specify project_metadata instead.\n",
      "  await eval(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'excellent-sweater-12' at:\n",
      "https://eu.smith.langchain.com/o/d3451cd8-cf10-4e87-b058-be401896eaf6/datasets/58cf4193-9ef4-4ef4-8591-aa0a4bb358f7/compare?selectedSessions=ca3b2224-458b-4b2d-a01a-3dc1c9cb5f49\n",
      "\n",
      "View all tests for Dataset calculator-example-dataset-1fa73a58-cda5-4249-921a-325fed3bcbd7 at:\n",
      "https://eu.smith.langchain.com/o/d3451cd8-cf10-4e87-b058-be401896eaf6/datasets/58cf4193-9ef4-4ef4-8591-aa0a4bb358f7\n",
      "[------------------->                              ] 4/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example a6f75e18-aec7-4d55-a8a0-fb575cba68a4 with inputs {'input': 'What is 10 raised to power of 20?'}\n",
      "ValueError('LLMMathChain._evaluate(\"\\n10**20\\n\") raised error: Python int too large to convert to C long. Please try again with a valid numerical expression')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 10/10"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.fifth-grader-score</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LLMMathChain._evaluate(\"\\n10**20\\n\") raised er...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84c0b0da-635b-4597-a294-f21528d10633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.242218</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.013710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.440959</td>\n",
       "      <td>0.049401</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.220173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.079506</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.248332</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.747456</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.750314</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.503158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.correctness  feedback.embedding_cosine_distance  \\\n",
       "count               9.000000                            9.000000   \n",
       "unique                   NaN                                 NaN   \n",
       "top                      NaN                                 NaN   \n",
       "freq                     NaN                                 NaN   \n",
       "mean                0.222222                            0.242218   \n",
       "std                 0.440959                            0.049401   \n",
       "min                 0.000000                            0.186911   \n",
       "25%                 0.000000                            0.207105   \n",
       "50%                 0.000000                            0.231350   \n",
       "75%                 0.000000                            0.247677   \n",
       "max                 1.000000                            0.344992   \n",
       "\n",
       "        feedback.helpfulness  feedback.fifth-grader-score  \\\n",
       "count               9.000000                     9.000000   \n",
       "unique                   NaN                          NaN   \n",
       "top                      NaN                          NaN   \n",
       "freq                     NaN                          NaN   \n",
       "mean                0.666667                     0.666667   \n",
       "std                 0.500000                     0.500000   \n",
       "min                 0.000000                     0.000000   \n",
       "25%                 0.000000                     0.000000   \n",
       "50%                 1.000000                     1.000000   \n",
       "75%                 1.000000                     1.000000   \n",
       "max                 1.000000                     1.000000   \n",
       "\n",
       "                                                    error  execution_time  \\\n",
       "count                                                   1       10.000000   \n",
       "unique                                                  1             NaN   \n",
       "top     LLMMathChain._evaluate(\"\\n10**20\\n\") raised er...             NaN   \n",
       "freq                                                    1             NaN   \n",
       "mean                                                  NaN       53.013710   \n",
       "std                                                   NaN       22.220173   \n",
       "min                                                   NaN       26.079506   \n",
       "25%                                                   NaN       40.248332   \n",
       "50%                                                   NaN       47.747456   \n",
       "75%                                                   NaN       53.750314   \n",
       "max                                                   NaN       99.503158   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     10  \n",
       "unique                                    10  \n",
       "top     84c0b0da-635b-4597-a294-f21528d10633  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.smith import (\n",
    "    arun_on_dataset,\n",
    "    run_on_dataset, \n",
    ")\n",
    "\n",
    "chain_results = await arun_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=agent_factory,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    tags=[\"testing-notebook\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d94f38-efa3-4358-b35b-85f5b1136c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
